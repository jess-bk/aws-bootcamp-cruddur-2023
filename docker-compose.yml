version: "3.8"

services:
  backend-flask:
    environment:
      FRONTEND_URL: "https://3000-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}"
      BACKEND_URL: "https://4567-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}"
      # FRONTEND_URL: "https://${CODESPACE_NAME}-3000.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}"
      # BACKEND_URL: "https://${CODESPACE_NAME}-4567.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}"
      OTEL_SERVICE_NAME: "backend-flask"
      OTEL_EXPORTER_OTLP_ENDPOINT: "https://api.honeycomb.io"
      OTEL_EXPORTER_OTLP_HEADERS: "x-honeycomb-team=${HONEYCOMB_API_KEY}"
      AWS_XRAY_URL: "*4567-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}*"
      OTEL_RESOURCE_ATTRIBUTES: "service.name=backend-flask"
      AWS_XRAY_DAEMON_ADDRESS: "xray-daemon:2000"
      AWS_DEFAULT_REGION: "${AWS_DEFAULT_REGION}"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      ROLLBAR_ACCESS_TOKEN: "${ROLLBAR_ACCESS_TOKEN}"
      AWS_COGNITO_USER_POOL_ID: "us-east-1_FpcgxtNfc"
      AWS_COGNITO_USER_POOL_CLIENT_ID: "6jbj9dn4cf8oldfrvmm5cg34t9"
    build: ./backend-flask
    ports:
      - "4567:4567"
    volumes:
      - ./backend-flask:/backend-flask
    healthcheck:
      test: ["CMD-SHELL", "curl --fail http://localhost:4567/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
  frontend-react-js:
    environment:
      REACT_APP_BACKEND_URL: "https://4567-${GITPOD_WORKSPACE_ID}.${GITPOD_WORKSPACE_CLUSTER_HOST}"
      # REACT_APP_BACKEND_URL: "https://${CODESPACE_NAME}-4567.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}"
      OTEL_RESOURCE_ATTRIBUTES: "service.name=frontend-react-js"
      # OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4318"
      OTEL_EXPORTER_OTLP_ENDPOINT: "https://api.honeycomb.io"
      REACT_APP_AWS_PROJECT_REGION: "${AWS_DEFAULT_REGION}"
      REACT_APP_AWS_COGNITO_REGION: "${AWS_DEFAULT_REGION}"
      REACT_APP_AWS_USER_POOLS_ID: "us-east-1_FpcgxtNfc"
      REACT_APP_CLIENT_ID: "6jbj9dn4cf8oldfrvmm5cg34t9"
    build:
      context: ./frontend-react-js
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      - ./frontend-react-js:/frontend-react-js
    command: sh -c "npm i && npm start"
    depends_on:
      - backend-flask
    networks:
      - internal-network

  otel-collector:
    environment:
      FRONTEND_URL: "https://${CODESPACE_NAME}-3000.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}"
      BACKEND_URL: "https://${CODESPACE_NAME}-4567.${GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}"
      HONEYCOMB_API_KEY: "${HONEYCOMB_API_KEY}"
    image: otel/opentelemetry-collector
    command: [--config=/otel-collector-config.yaml]
    volumes:
      - "./otel-collector-config.yaml:/otel-collector-config.yaml"
    ports:
      - 4318:4318
    networks:
      - internal-network

  # custom-proxy:
  #   image: nginx:latest
  #   volumes:
  #     - ./custom-proxy.conf:/custom-proxy.conf
  #   ports:
  #     - "8123:80"
  #   networks:
  #     - internal-network

  xray-daemon:
    image: "amazon/aws-xray-daemon"
    environment:
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_REGION: "us-east-1"
    command:
      - "xray -o -b xray-daemon:2000"
    ports:
      - 2000:2000/udp
  # dynamodb-local:
  #   # https://stackoverflow.com/questions/67533058/persist-local-dynamodb-data-in-volumes-lack-permission-unable-to-open-databa
  #   # We needed to add user:root to get this working.
  #   user: root
  #   command: "-jar DynamoDBLocal.jar -sharedDb -dbPath ./data"
  #   image: "amazon/dynamodb-local:latest"
  #   container_name: dynamodb-local
  #   ports:
  #     - "8000:8000"
  #   volumes:
  #     - "./docker/dynamodb:/home/dynamodblocal/data"
  #   working_dir: /home/dynamodblocal
  #   healthcheck:
  #     test:
  #       [
  #         "CMD-SHELL",
  #         "aws dynamodb list-tables --endpoint-url http://localhost:8000",
  #       ]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 3
  db:
    image: postgres:13-alpine
    restart: always
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    ports:
      - "5432:5432"
    volumes:
      - db:/var/lib/postgresql/data

# the name flag is a hack to change the default prepend folder
# name when outputting the image names
networks:
  internal-network:
    driver: bridge
    name: cruddur

volumes:
  db:
    driver: local
